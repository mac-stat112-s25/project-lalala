---
title: "Report"
execute: 
  echo: true      # change to true to show the code
code-fold: false  # change to true to fold the code chunks
---


## Introduction
The first Assassin's Creed game was released in 2007, and since has become a flagship title for Ubisoft, the publishers of the game. In order to complete the main story and extra content of the game, it's estimated that it would take you 20 hours total, which was typical of games then. Fast forward 13 years later, and 2020's Assassin's Creed: Valhalla's main story and side missions are estimated to take a total of 100 hours. When released, Valhalla was a notable outlier for its massive time to beat. But while most games don't strive to be *that* long, trends in gaming have made it so a long time to beat is a prized ideal for some developers. However, this strive to make the game with the most content possible comes at a cost. The price of game development has only gotten higher with time, and most companies cannot afford to pack a product with such a high amount of unique content. But neither did Assassin's Creed Valhalla! A growing issue in the modern video game market is to have games released with around 20 hours of original unique content, and have the rest of the playtime be taken up with the same missions, assets, and content slightly copied and pasted somewhere else. 

## Research Question
Depending on where you get your video game reviews from, it may not be apparent just how much bloat a game might be filled with. Alongside it, some reviewers may simply look at the playtime without considering how much of it is unique, causing this bloat to go unseen. Every gamer has their own preferences on how long they like their games to be, but so does every reviewer. In hopes of painting a fuller picture of this subject, we took data from Howlongtobeat and Metacritic in order to answer our research question: *do longer video games get better review scores?*

## Background
For more context on our chosen sources...

### Howlongtobeat
Howlongtobeat is a video game cataloging service that, unsurprisingly, tracks how long a video game is to beat. One problem about measuring playtime is that each person completes games at their own speed, so using a service like Howlongtobeat allows us to get a much more accurate average based on user submissions than one person giving their feedback.

### Metacritic
Metacritic is a aggregate review site for Movies, Music, TV, and critically, Video Games. Instead of hosting their own reviews, the sole purpose of Metacritic is to create a hub where every reviewer's score resides, creating a highly utilized value in game discourse: the Metascore (essentially just a weighted average). Among that score, there are two values to take note of: The *critic score* is a 0 <-> 100 value that averages the scores of review outlet ratings of a title, and the *user score*, a 0 <-> 10 value that averages the reviews left by Metacritic users. 

## Data
For our project we joined 2 Kaggle datasets: one for Howlongtobeat times, and one for Metacritic scores. For Howlongtobeat, the dataset was collected by Kasumil5x in 2020 by scraping the official HLTB website. The dataset contained more information than we needed; Alongside with the Title and Main Story playtime, it also contained the developers, whether it was an expansion, and a multitude of other playtimes that weren't applicable to our project (how long it would take to 100% comple a game, and how long a co-op mode would take to complete (if it was included)). 
Our Metacritic dataset was made by Deep Contractor in 2022, by scraping directly from the Metacritic website. Alongside game title, user score, and critic score, the dataset also included which gaming platform it was released for, a summary of the game, and the release date. That last value (with a little wrangling) became a very helpful way of comparing how playtimes have changed over time. With a simple left_join by name and an extra mutate variable for yearly review averages, our dataset was ready!

```{r}
library(tidyverse)
library(scales)
library(ggridges)
hltb <- read_csv("data//all-completions.csv")
games <- read_csv("data//games.csv")
metac <- read.csv("data//all_games.csv")
realgames <- games |>
  mutate(name = title) |>
  select(name, main_story, main_plus_extras, completionist, all_styles, type, platforms, genres)

palala <- metac |>
  inner_join(realgames) |>
  mutate(gaga = release_date) |>
  separate(gaga, c("semester", "year"), "(?<=[,])") |>
  mutate(release_year = str_replace(year, " ", "")) |>
  mutate(user_review = as.integer(user_review)) |>
  select(-summary, -platform, -semester, -year) 

USETHISONE <- palala[!duplicated(palala$name), ]
#same as elina's code but i use inner_join and drop_na to exclude NAs so that my categories work properly

withcats <- USETHISONE |>
  drop_na(main_story) |>
  mutate(main_cat = case_when(
    (main_story <=2) ~ "nothing",
    (main_story <= 4 & main_story >2) ~ "tiny",
    (main_story <= 10 & main_story >7) ~ "medium",
    (main_story < 14 & main_story > 10) ~ "long",
    (main_story < 25 & main_story >=14) ~ "huge",
    (main_story >= 25) ~ "epic",
    .default = "short"
  )) |>
    mutate(main_cat = fct_relevel(main_cat, c("nothing", "tiny", "short", "medium", "long", "huge", "epic"))) |>
  #creates time based categories, subjective and mostly based on strandard distribution quantiles
mutate(meta_cat = case_when(
    (meta_score <=40) ~ "shovelware",
    (meta_score <= 60 & meta_score >40) ~ "questionable",
    (meta_score < 70 & meta_score >60) ~ "mixed",
    (meta_score < 84 & meta_score > 78) ~ "great",
    (meta_score < 90 & meta_score >=84) ~ "beloved",
    (meta_score >= 90) ~ "legendary",
    .default = "good"
)) |>
    mutate(meta_cat = fct_relevel(meta_cat, c("shovelware", "questionable", "mixed", "good", "great", "beloved", "legendary")))
#creates score based categories, mostly subjective
```
